Project components:
0. Find a focused web crawler that retrieves HTML pages and write code to convert them to DOM trees
1. Process text of page by stemming/word stop removal, tokenization, and normalization as described in section 4.3.* of the paper
2. Finding maximum common subgraph between to website graph representations via ISMAGS algorithm
3a. Retrieving most relavant page as determined by search engine
3b. Using the metric specified in the crawl-shing paper to determine the website similarity

The components are expected to interface in the following ways:
[0] will pass the retrieved wepage to [3]. [3] will return the relevant webpage to [0]
[0] will pass a SINGLE DOM representation webpage to [1]. [1] will return the processed webpage in a manner that is compatible with [2]'s interface
[0] will pass both processed graph webpages to [2], which will return the maximum commond subgraph
[0] will pass the maximum common subgraph along with the two webpages to [3]. [3] will return a similarity score
